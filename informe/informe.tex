\documentclass[11pt, a4paper, twoside]{article} % o book si es muy extenso
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern} % Fuente moderna y legible
\usepackage{microtype} % Mejora el espaciado y la justificación
\usepackage{geometry} % Para controlar los márgenes
    \geometry{
        a4paper,
        top=2.5cm,
        bottom=2.5cm,
        left=3cm,
        right=2.5cm,
        headheight=14pt,
        footskip=1.2cm
    }
\usepackage{fancyhdr} % Para personalizar encabezados y pies de página
\usepackage{graphicx} % Para incluir imágenes
\usepackage{hyperref} % Para enlaces interactivos y metadatos
    \hypersetup{
        colorlinks=true,
        linkcolor=blue,
        filecolor=magenta,
        urlcolor=cyan,
        pdftitle={Título de tu Proyecto},
        pdfauthor={Tu Nombre},
        pdfsubject={Informe de Proyecto Escolar},
        pdfkeywords={Proyecto, Escuela, Informe, LaTeX},
        bookmarks=true,
        bookmarksopen=true,
        bookmarksnumbered=true,
    }
\usepackage{titlesec} % Para personalizar títulos de secciones
\usepackage{enumitem} % Para personalizar listas
\usepackage{setspace} % Para controlar el interlineado
    \onehalfspacing % Interlineado de 1.5 para mejor lectura
\usepackage{listings}
\usepackage{xcolor} % Asegúrate de tenerlo para los colores

% --- Configuración de listings para código ---
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize, % Fuente monoespaciada, tamaño pequeño
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left, % Números de línea a la izquierda
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2, % Tamaño de la tabulación
    frame=single, % Marco alrededor del código
    rulecolor=\color{black},
    frameround=tttt, % Esquinas redondeadas
    extendedchars=true, % Para caracteres extendidos (como 'ñ')
    literate={á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1 {ñ}{{\~n}}1 % Para manejar tildes y eñes
}

\lstset{style=mystyle} % Aplicar el estilo por defecto
\usepackage{lastpage} % Para obtener el número total de páginas

% --- Personalización de títulos de secciones ---
\titleformat{\section}[block]
  {\normalfont\Large\bfseries\color{green!70!black}}
  {\thesection}{1em}{}
\titlespacing*{\section}
  {0pt}{1.5ex plus .1ex minus .2ex}{1ex plus .1ex}

\titleformat{\subsection}[block]
  {\normalfont\large\bfseries\color{blue!50!black}}
  {\thesubsection}{1em}{}
\titlespacing*{\subsection}
  {0pt}{1.5ex plus .1ex minus .2ex}{1ex plus .1ex}

% --- Configuración de encabezados y pies de página ---
\pagestyle{fancy}
\fancyhf{} % Borra los ajustes predeterminados
\fancyhead[RO,LE]{\thepage} % Número de página a la derecha en páginas impares, a la izquierda en pares
\fancyhead[LO]{\nouppercase{\rightmark}} % Título de la sección en la parte izquierda (páginas impares)
\fancyhead[RE]{\nouppercase{\leftmark}} % Título del capítulo en la parte derecha (páginas pares) (si usas 'book' o 'report')
\fancyfoot[C]{\textbf{Informe de Proyecto}} % Texto en el pie de página centrado
\renewcommand{\headrulewidth}{0.4pt} % Línea en el encabezado
\renewcommand{\footrulewidth}{0.4pt} % Línea en el pie de página

\begin{document}

\thispagestyle{empty} % Para que la primera página no tenga encabezado ni pie de página

\begin{titlepage}
    \begin{center}

        % --- Título del Proyecto ---
        {\color{green!80!black}\Huge\bfseries Compilador de HULK}\par
        \vspace{0.5cm}

        % --- Integrantes del Equipo ---
        {\Large\bfseries Integrantes:}\par
        \vspace{0.3cm} % Espacio entre "Integrantes:" y los nombres
        {\large  Lia S. Lope\'ez Rosales C312}\par
        {\large  Ariadna Vel\'azquez Rey C311}\par
        \vspace{1.5cm} % Espacio después de los nombres

        % --- Información del Curso/Asignatura ---
        {\large Asignatura: Compilaci\'on}\par
        {\large Universidad de La Habana}\par
        \vspace{0.5cm}

        % --- Fecha ---
        {\large \today}\par % Muestra la fecha actual
        \vfill % Empuja el contenido restante hacia abajo


    \end{center}
\end{titlepage}

\clearpage
% ... (el resto de tu documento sigue aquí, como la tabla de contenido y las secciones)

\clearpage % Para empezar el contenido en una nueva página
% Aquí puedes incluir tu tabla de contenido, si la necesitas:
% \tableofcontents
% \clearpage

% --- Comienza el contenido de tu informe ---
\section{Introducción}
Este informe describe el proceso de creación de un compilador para el lenguaje HULK (Havana University Language for Kompilers)
utilizando como lenguaje base C++.

El compilador está diseñado siguiendo una arquitectura modular que divide el proceso de compilación en etapas bien definidas, cada una con responsabilidades específicas y mecanismos de manejo de errores robustos.

\subsection{Flujo del Programa}
El flujo del programa sigue una secuencia modular y estructurada de etapas de compilación, coordinadas desde la función principal en \texttt{main.cpp}. Cada etapa utiliza componentes propios implementados en C++ puro, sin herramientas externas. El procedimiento real es el siguiente:

\begin{enumerate}
    \item \textbf{Inicialización}:
    \begin{itemize}
        \item Procesamiento de argumentos de línea de comandos para determinar el archivo fuente (por defecto, \texttt{script.hulk})
        \item Lectura y validación del archivo fuente mediante la función \texttt{readFile()}
    \end{itemize}

    \item \textbf{Análisis Léxico}:
    \begin{itemize}
        \item Instanciación de la clase \texttt{Lexer} con el código fuente
        \item Generación secuencial de tokens usando \texttt{nextToken()}, almacenando cada token en un vector
        \item Reporte inmediato de errores léxicos mediante \texttt{getErrors()}; si existen, el programa termina
    \end{itemize}

    \item \textbf{Carga y Construcción de la Gramática}:
    \begin{itemize}
        \item Instanciación de \texttt{GrammarAugment} y carga de la gramática BNF desde archivo
        \item Cálculo de conjuntos \texttt{FIRST} y \texttt{FOLLOW}
        \item Construcción de conjuntos de items LR(1) con \texttt{LR1ItemSetBuilder}
        \item Generación de tablas de parsing (\texttt{ACTION} y \texttt{GOTO}) con \texttt{LR1ParsingTableGenerator}, configurando precedencias
    \end{itemize}

    \item \textbf{Parsing y Construcción del AST}:
    \begin{itemize}
        \item Instanciación de \texttt{SemanticActionDispatcher} para asociar acciones semánticas
        \item Instanciación de \texttt{ParserDriver} y ejecución del ciclo de parsing LR(1) sobre la lista de tokens
        \item Construcción del AST y acumulación de errores sintácticos
        \item Validación del AST generado (no vacío, sin nodos nulos)
        \item Reporte de errores sintácticos; si existen, el programa termina
    \end{itemize}

    \item \textbf{Impresión del AST}:
    \begin{itemize}
        \item Impresión de la estructura del AST usando \texttt{ASTPrinter} para diagnóstico
    \end{itemize}

    \item \textbf{Análisis Semántico}:
    \begin{itemize}
        \item Instanciación de \texttt{SemanticAnalyzer} y análisis del AST
        \item Gestión de ámbitos, variables, funciones y tipos mediante \texttt{SymbolTable}
        \item Reporte de errores semánticos si existen
    \end{itemize}

    \item \textbf{Generación de Código LLVM}:
    \begin{itemize}
        \item Instanciación de \texttt{CodeGenContext}, que encapsula el contexto de generación y el sistema de tipos
        \item Generación de código LLVM IR recorriendo el AST
        \item Volcado del IR generado en el archivo \texttt{hulk-low-code.ll}
    \end{itemize}

    \item \textbf{Finalización}:
    \begin{itemize}
        \item El programa termina exitosamente si no hubo errores fatales en ninguna etapa
    \end{itemize}
\end{enumerate}

En cada etapa, el compilador implementa un manejo de errores robusto que permite:
\begin{itemize}
    \item Detección temprana y reporte inmediato de problemas léxicos, sintácticos y semánticos
    \item Mensajes de error descriptivos con información de ubicación precisa
    \item Limpieza apropiada de recursos en caso de fallo
    \item Códigos de retorno específicos para diferentes tipos de error
\end{itemize}


\section{Análisis Léxico: Lexer}

El analizador léxico del compilador \textbf{HULK} está implementado completamente en C++ mediante una clase propia \texttt{Lexer}, sin utilizar Flex ni generadores automáticos. El diseño se basa en un autómata manual que recorre el texto fuente carácter por carácter, identificando tokens y gestionando errores de manera precisa y eficiente.

\subsection{Estructura e Interfaz}

El lexer se encapsula en la clase \texttt{Lexer}, que recibe el código fuente como una cadena y expone el método principal \texttt{nextToken()}, encargado de devolver el siguiente token del flujo. Cada token se representa mediante la estructura \texttt{Token}, que almacena el tipo (\texttt{TokenType}), el lexema y la ubicación exacta (línea y columna) en el código fuente. Los errores léxicos se encapsulan en la estructura \texttt{LexerError}, que incluye mensaje, ubicación y el lexema problemático.

\subsection{Lógica de Tokenización y Autómata}

El proceso de análisis léxico se realiza mediante un autómata implementado manualmente, con funciones especializadas para cada tipo de patrón:

\begin{itemize}
    \item \textbf{Identificadores y Palabras Clave}: Reconocidos por el método \texttt{identifierOrKeyword()}, que detecta patrones del tipo \texttt{[a-zA-Z\_][a-zA-Z0-9\_]*} y los compara contra un mapa de palabras clave para distinguirlos de identificadores.
    \item \textbf{Números}: El método \texttt{number()} reconoce literales numéricos enteros y decimales, permitiendo la presencia de un punto decimal.
    \item \textbf{Cadenas}: El método \texttt{stringLiteral()} reconoce literales de cadena delimitadas por comillas dobles, preservando secuencias de escape y reportando errores en caso de cadenas sin cerrar.
    \item \textbf{Operadores y Puntuación}: El método \texttt{matchOperator()} detecta operadores de uno o dos caracteres (como \texttt{==}, \texttt{!=}, \texttt{@@}, etc.) y signos de puntuación mediante análisis por adelantado y un switch eficiente.
    \item \textbf{Espacios en Blanco}: El método \texttt{skipWhitespace()} omite espacios, tabulaciones y saltos de línea antes de analizar el siguiente token.
\end{itemize}

\subsection{Tipos de Tokens y Estructura}

El enum \texttt{TokenType} define todos los tipos de tokens reconocidos, incluyendo:
\begin{itemize}
    \item Literales: números, cadenas, booleanos, nulo, identificadores
    \item Operadores aritméticos, lógicos, de comparación y concatenación
    \item Palabras clave del lenguaje (control de flujo, declaración, POO, funciones matemáticas, constantes)
    \item Signos de puntuación y operadores especiales
    \item Token especial para fin de archivo y para símbolos desconocidos
\end{itemize}

Cada token almacena su lexema y la ubicación exacta (línea y columna) donde fue encontrado, facilitando el diagnóstico y reporte de errores.

\subsection{Manejo de Errores}

El lexer implementa un sistema robusto de manejo de errores léxicos:
\begin{itemize}
    \item \textbf{Reporte Inmediato}: Ante símbolos no reconocidos, cadenas sin cerrar o tokens malformados, se genera un \texttt{LexerError} con mensaje descriptivo, ubicación y el lexema problemático.
    \item \textbf{Acumulación de Errores}: Todos los errores detectados se almacenan y pueden ser consultados tras el análisis mediante \texttt{getErrors()}.
    \item \textbf{Precisión}: Cada error incluye la línea y columna exacta, permitiendo mensajes claros y útiles para el usuario.
\end{itemize}

\subsection{Características Especiales y Extensibilidad}

\begin{itemize}
    \item \textbf{Seguimiento de Ubicación}: El lexer actualiza línea y columna en cada avance, asegurando precisión en la localización de tokens y errores.
    \item \textbf{Gestión de Strings}: Las cadenas preservan los caracteres de escape y eliminan automáticamente las comillas delimitadoras.
    \item \textbf{Modularidad}: La implementación en C++ puro facilita la extensión para nuevos tipos de tokens o reglas léxicas.
    \item \textbf{Integración}: El lexer está diseñado para integrarse fácilmente con el parser y el resto del compilador, proporcionando tokens y errores con toda la información contextual necesaria.
\end{itemize}

\section{An\'alisis Sint\'actico: Parser}

El analizador sintáctico del compilador \textbf{HULK} está implementado como un generador LR(1) propio en C++, que abarca desde la normalización de la gramática hasta la ejecución del autómata y la construcción del AST. El sistema es completamente modular y extensible, y no depende de herramientas externas como Bison.

\subsection{Flujo de Generación del Parser}

El proceso de generación y ejecución del parser se compone de varias etapas bien diferenciadas:

\begin{enumerate}
    \item \textbf{Normalización de Gramática (EBNF a BNF):}
    \begin{itemize}
        \item El archivo de gramática fuente se escribe en EBNF para mayor expresividad.
        \item El módulo \texttt{GrammarNormalizer} convierte automáticamente la EBNF a BNF, generando reglas auxiliares para secuencias, alternativas, repeticiones y opcionales.
        \item El resultado es una lista de reglas BNF listas para la construcción del autómata.
    \end{itemize}

    \item \textbf{Construcción y Augmentación de la Gramática:}
    \begin{itemize}
        \item El objeto \texttt{GrammarAugment} lee la gramática BNF, identifica terminales y no terminales, y realiza la augmentación necesaria para LR(1).
        \item Calcula los conjuntos \texttt{FIRST} y \texttt{FOLLOW} para todos los símbolos, fundamentales para la predicción y la construcción de items LR(1).
    \end{itemize}

    \item \textbf{Construcción del Autómata LR(1):}
    \begin{itemize}
        \item El \texttt{LR1ItemSetBuilder} genera el conjunto de estados del autómata LR(1) a partir de la gramática augmentada.
        \item Cada estado es un conjunto de items LR(1), definidos por la posición del punto y el lookahead.
        \item Se implementa el algoritmo de \textbf{closure} para expandir los items y el de \textbf{goto} para construir las transiciones entre estados.
        \item Se utiliza una caché para optimizar la computación de closures.
    \end{itemize}

    \item \textbf{Generación de Tablas de Parsing:}
    \begin{itemize}
        \item El \texttt{LR1ParsingTableGenerator} recorre los estados del autómata y genera las tablas \texttt{ACTION} y \texttt{GOTO}.
        \item Se resuelven automáticamente los conflictos shift/reduce y reduce/reduce usando precedencia y asociatividad, configuradas explícitamente en el código.
        \item Se almacena, para cada estado, el conjunto de tokens esperados, facilitando la recuperación y reporte de errores.
    \end{itemize}

    \item \textbf{Ejecución del Parser:}
    \begin{itemize}
        \item El \texttt{ParserDriver} implementa el ciclo de parsing LR(1) clásico: mantiene una pila de estados y una pila de valores semánticos.
        \item Para cada token, consulta la tabla \texttt{ACTION} para decidir entre shift, reduce, accept o error.
        \item Las reducciones invocan acciones semánticas a través del \texttt{SemanticActionDispatcher}, que construye el AST de manera incremental.
        \item El parser soporta recuperación de errores y sincronización mediante tokens especiales (como punto y coma).
    \end{itemize}
\end{enumerate}

\subsection{Automatización y Manipulación de Autómatas}

\begin{itemize}
    \item \textbf{Items LR(1):} Cada item se representa como una tupla \texttt{(lhs, rhs, dot, lookahead)}. El closure expande los items considerando los lookaheads, siguiendo el algoritmo estándar de LR(1).
    \item \textbf{Closure y Goto:} El closure se implementa de forma iterativa y eficiente, utilizando caché para evitar recomputaciones. El goto genera nuevos kernels y expande el autómata.
    \item \textbf{Transiciones:} Las transiciones entre estados se almacenan en una tabla de mapeo, permitiendo la navegación eficiente durante el parsing.
\end{itemize}

\subsection{Tablas y Resolución de Conflictos}

\begin{itemize}
    \item \textbf{Tabla ACTION:} Para cada estado y símbolo terminal, se almacena la acción a realizar (shift, reduce, accept o error).
    \item \textbf{Tabla GOTO:} Para cada estado y no terminal, se almacena el siguiente estado tras una reducción.
    \item \textbf{Precedencia y Asociatividad:} Los conflictos se resuelven usando precedencia y asociatividad configurables, permitiendo un control fino sobre el comportamiento del parser.
    \item \textbf{Tokens Esperados:} Se mantiene, para cada estado, el conjunto de tokens válidos, lo que permite mensajes de error precisos y sugerencias de recuperación.
\end{itemize}

\subsection{Construcción del AST y Acciones Semánticas}

\begin{itemize}
    \item \textbf{Dispatcher de Acciones:} El \texttt{SemanticActionDispatcher} asocia cada producción con una acción semántica, que puede construir nodos del AST, listas, o realizar validaciones.
    \item \textbf{Pila de Valores:} El parser utiliza una pila de valores polimórficos (\texttt{ParserValue}) para manejar tokens, nodos AST y listas de nodos.
    \item \textbf{Integración con el AST:} Cada reducción puede crear o combinar nodos del AST, permitiendo la construcción incremental y modular del árbol sintáctico.
\end{itemize}

\subsection{Ventajas y Características Especiales}

\begin{itemize}
    \item \textbf{Modularidad Total:} Cada componente (normalización, augmentación, autómata, tablas, parser) es independiente y extensible.
    \item \textbf{Diagnóstico y Depuración:} El sistema permite imprimir los conjuntos de items, las tablas de parsing y los tokens esperados, facilitando la depuración y el análisis de la gramática.
    \item \textbf{Recuperación de Errores:} El parser implementa mecanismos de recuperación y sincronización, permitiendo continuar el análisis tras errores sintácticos.
    \item \textbf{Extensibilidad:} Es sencillo añadir nuevas reglas, operadores o modificar la gramática, gracias a la separación clara de responsabilidades y la automatización de la normalización y generación de tablas.
\end{itemize}

\section{Chequeo Sem\'antico}
El chequeo sem\'antico en el compilador \textbf{HULK} se implementa mediante un sistema sofisticado que utiliza el \textbf{Patr\'on Visitor} para recorrer y analizar el AST. La implementación se divide en varios componentes principales que trabajan en conjunto para garantizar la corrección semántica del programa.

\subsection{Componentes Principales}

\begin{itemize}
    \item \textbf{SemanticAnalyzer}: Implementa el patrón Visitor y coordina todo el análisis semántico.
    \item \textbf{SymbolTable}: Gestiona los símbolos y ámbitos del programa.
    \item \textbf{FunctionCollector}: Recolecta y analiza las declaraciones de funciones.
\end{itemize}

\subsection{Tabla de S\'imbolos}

La tabla de símbolos (\texttt{SymbolTable}) es una estructura sofisticada que maneja:

\begin{itemize}
    \item \textbf{\'Ambitos Anidados}:
    \begin{itemize}
        \item Vector de mapas para manejar ámbitos (\texttt{scopes})
        \item Métodos \texttt{enterScope()} y \texttt{exitScope()} para gestión de ámbitos
        \item Búsqueda de símbolos en ámbitos anidados
    \end{itemize}

    \item \textbf{Tipos de S\'imbolos}:
    \begin{itemize}
        \item Variables con tipo y estado de constante
        \item Funciones con tipo de retorno y parámetros
        \item Tipos definidos por el usuario con atributos y métodos
    \end{itemize}

    \item \textbf{Tipos Predefinidos}:
    \begin{itemize}
        \item Object, Number, String, Boolean, Null
        \item Jerarquía de tipos y relaciones de subtipado
    \end{itemize}
\end{itemize}

\subsection{An\'alisis de Tipos}

El sistema implementa un sofisticado análisis de tipos que incluye:

\begin{itemize}
    \item \textbf{Inferencia de Tipos}:
    \begin{itemize}
        \item Análisis de uso de parámetros en el cuerpo de funciones
        \item Inferencia basada en operaciones y contexto
        \item Resolución de tipos más específicos comunes
    \end{itemize}

    \item \textbf{Verificaci\'on de Operaciones}:
    \begin{itemize}
        \item Operaciones aritméticas (\texttt{+}, \texttt{-}, \texttt{*}, \texttt{/}, \texttt{\%})
        \item Operaciones de comparación (\texttt{>}, \texttt{<}, \texttt{>=}, \texttt{<=})
        \item Operaciones lógicas (\texttt{\&}, \texttt{|}, \texttt{!})
        \item Concatenación de strings (\texttt{@}, \texttt{@@})
    \end{itemize}

    \item \textbf{Jerarqu\'ia de Tipos}:
    \begin{itemize}
        \item Verificación de conformidad de tipos (\texttt{conformsTo})
        \item Búsqueda del ancestro común más bajo (\texttt{lowestCommonAncestor})
        \item Manejo de herencia
    \end{itemize}
\end{itemize}

\subsection{Validaci\'on Sem\'antica}

El analizador semántico realiza múltiples validaciones:

\begin{itemize}
    \item \textbf{Declaraciones}:
    \begin{itemize}
        \item Unicidad de nombres en el ámbito actual
        \item Tipos correctos en declaraciones
    \end{itemize}

    \item \textbf{Funciones}:
    \begin{itemize}
        \item Compatibilidad de tipos en argumentos
        \item Inferencia de tipos de retorno
        \item Validación de funciones matemáticas built-in
    \end{itemize}

    \item \textbf{Programaci\'on Orientada a Objetos}:
    \begin{itemize}
        \item Declaración y uso de tipos
        \item Validación de herencia
        \item Llamadas a métodos y constructores
        \item Acceso a atributos
    \end{itemize}

    \item \textbf{Control de Flujo}:
    \begin{itemize}
        \item Tipos correctos en condiciones
        \item Validación de bucles
        \item Comprobación de expresiones let-in
    \end{itemize}
\end{itemize}


\section{Generación de Código LLVM}

La generación de código intermedio en el compilador \textbf{Hulk} se realiza utilizando \textbf{LLVM IR} (Intermediate Representation). El sistema está diseñado de manera modular, con una clara separación de responsabilidades entre la generación de código, el manejo de tipos y el contexto de generación.

\subsection{Componentes Principales}

La implementación se divide en tres componentes principales:

\begin{itemize}
    \item \textbf{LLVMGenerator}: Implementa el patrón Visitor para recorrer el AST y generar código LLVM IR.
    \item \textbf{CodeGenContext}: Encapsula todo el estado y contexto necesario para la generación de código.
    \item \textbf{TypeSystem}: Maneja el sistema de tipos, incluyendo definiciones de tipos y sus instancias.
\end{itemize}

\subsection{Estructura del Generador}

El generador de código (\texttt{LLVMGenerator}) implementa el patrón Visitor y proporciona métodos específicos para cada tipo de nodo del AST:

\begin{itemize}
    \item Manejo de literales (números, booleanos, strings)
    \item Operaciones binarias y unarias
    \item Funciones built-in y definidas por el usuario
    \item Estructuras de control (if, while, for)
    \item Soporte para POO (declaración de tipos, instanciación, llamadas a métodos)
\end{itemize}

\subsection{Contexto de Generación}

El \texttt{CodeGenContext} mantiene el estado durante la generación de código:

\begin{itemize}
    \item \textbf{Estado LLVM}: Contexto global, builder y módulo
    \item \textbf{Gestión de Ámbitos}: Pilas para variables locales y funciones
    \item \textbf{Sistema de Tipos}: Integración con el sistema de tipos para POO
    \item \textbf{Pila de Valores}: Mecanismo para pasar valores entre nodos durante el recorrido del AST
\end{itemize}

\subsection{Sistema de Tipos}

El \texttt{TypeSystem} proporciona soporte completo para POO:

\begin{itemize}
    \item Definición de tipos con atributos y métodos
    \item Soporte para herencia
    \item Gestión de instancias y sus variables
    \item Manejo de constructores y llamadas base
\end{itemize}

\subsection{Flujo de Generación}

El proceso de generación sigue estos pasos:

\begin{enumerate}
    \item \textbf{Inicialización}:
    \begin{itemize}
        \item Configuración del contexto LLVM y builder
        \item Declaración de funciones externas (printf, malloc, operaciones matemáticas)
        \item Registro de tipos y funciones del usuario
    \end{itemize}
    
    \item \textbf{Generación de Código}:
    \begin{itemize}
        \item Recorrido del AST usando el patrón Visitor
        \item Generación de instrucciones LLVM para cada tipo de nodo
        \item Manejo de la pila de valores para comunicación entre nodos
    \end{itemize}
    
    \item \textbf{Gestión de Memoria}:
    \begin{itemize}
        \item Uso de \texttt{alloca} para variables locales
        \item Manejo de memoria para strings y objetos
        \item Gestión de ámbitos anidados
    \end{itemize}
    
    \item \textbf{Verificación}:
    \begin{itemize}
        \item Validación del módulo LLVM generado
        \item Generación del archivo IR final
    \end{itemize}
\end{enumerate}

\subsection{Ejemplo de Generación}

Consideremos la generación de código para una operación binaria:

\begin{enumerate}
    \item El visitor procesa recursivamente los operandos izquierdo y derecho
    \item Los valores resultantes se obtienen de la pila de valores
    \item Se genera la instrucción LLVM correspondiente según el operador
    \item El resultado se coloca en la pila para uso posterior
\end{enumerate}

Por ejemplo, para la expresión \texttt{a + b} donde ambos son números:

\begin{itemize}
    \item Se generan las cargas de las variables \texttt{a} y \texttt{b}
    \item Se crea una instrucción \texttt{fadd} usando el builder
    \item El resultado se almacena en la pila de valores
\end{itemize}

\section{Manejo de Errores}

El manejo de errores en el compilador \textbf{Hulk} está implementado de manera modular y robusta, con mecanismos específicos en cada fase de la compilación. El sistema está diseñado para detectar y reportar errores de manera precisa, proporcionando información detallada sobre la ubicación y naturaleza de cada error.

\subsection{Errores Léxicos}

El analizador léxico, implementado manualmente en C++ (sin Flex), incluye un sistema preciso de seguimiento de posición y manejo de errores:

\begin{itemize}
    \item \textbf{Seguimiento de Posición}: El lexer mantiene un registro exacto de línea y columna para cada token y error, actualizando estos valores a medida que avanza por el texto fuente.
    \item \textbf{Detección de Errores}:
    \begin{itemize}
        \item Símbolos no reconocidos (caracteres fuera del alfabeto del lenguaje)
        \item Literales de cadena sin cerrar
        \item Tokens malformados
    \end{itemize}
    \item \textbf{Reporte y Acumulación de Errores}: Cada vez que se detecta un error, se crea un objeto \texttt{LexerError} que almacena un mensaje descriptivo, la ubicación exacta (línea y columna) y el lexema problemático. Todos los errores se acumulan en un vector interno y pueden ser consultados tras el análisis mediante el método \texttt{getErrors()}.
    \item \textbf{Precisión}: La información de ubicación se gestiona manualmente, sin depender de herramientas externas, lo que permite mensajes de error claros y útiles para el usuario.
\end{itemize}

\subsection{Errores Sintácticos}

El parser, implementado como un autómata LR(1) propio en C++, gestiona los errores sintácticos de manera robusta y extensible:

\begin{itemize}
    \item \textbf{Detección de Errores}: Cuando se encuentra un token inesperado (no existe una acción válida para el estado actual y el token), el parser reporta el error, indicando el token problemático, su ubicación y el conjunto de tokens esperados.
    \item \textbf{Sincronización y Recuperación}: El parser implementa mecanismos de recuperación mediante la búsqueda de tokens de sincronización (como el punto y coma), permitiendo continuar el análisis tras un error y acumular múltiples errores en una sola pasada.
    \item \textbf{Acumulación de Errores}: Todos los errores sintácticos se almacenan en un vector interno y se reportan al finalizar el análisis.
    \item \textbf{Validación de AST}: Tras el análisis, se verifica la validez del árbol sintáctico generado, comprobando la ausencia de nodos nulos o estructuras incompletas, y reportando errores si es necesario.
    \item \textbf{Precisión}: La información de ubicación de los errores se obtiene directamente de los tokens, permitiendo mensajes detallados y precisos.
\end{itemize}

\subsection{Errores Semánticos}

El analizador semántico implementa un sistema sofisticado de detección y reporte de errores:

\begin{itemize}
    \item \textbf{Estructura de Error}:
    \begin{itemize}
        \item Clase \texttt{SemanticError} para encapsular errores
        \item Información de línea y mensaje descriptivo
        \item Acumulación de errores para reporte completo
    \end{itemize}

    \item \textbf{Tipos de Errores}:
    \begin{itemize}
        \item Errores de tipo en operaciones
        \item Variables no declaradas o mal utilizadas
        \item Errores en llamadas a funciones
        \item Problemas de herencia y tipos
    \end{itemize}

    \item \textbf{Recuperaci\'on}:
    \begin{itemize}
        \item Continuación del análisis tras errores
        \item Inferencia de tipos en casos ambiguos
        \item Manejo de tipos desconocidos
    \end{itemize}
\end{itemize}


\subsection{Errores en Generación de Código}

La fase de generación de código LLVM incluye:

\begin{itemize}
    \item \textbf{Manejo de Excepciones}: Captura y manejo de errores durante la generación.
    \item \textbf{Validación de IR}: Verificación del código LLVM generado.
    \item \textbf{Reporte de Errores}: Mensajes detallados sobre problemas en la generación.
\end{itemize}

\subsection{Integración en el Flujo Principal}

El \texttt{main.cpp} coordina el manejo de errores entre las diferentes etapas:

\begin{itemize}
    \item \textbf{Verificación Secuencial}:
    \begin{itemize}
        \item Validación de apertura de archivo
        \item Comprobación de errores léxicos
        \item Verificación de errores sintácticos
        \item Validación del AST generado
        \item Control de errores semánticos
        \item Manejo de errores en generación de código
    \end{itemize}
    \item \textbf{Limpieza de Recursos}: Liberación apropiada de memoria y recursos en caso de error.
    \item \textbf{Códigos de Retorno}: Uso de códigos de salida para indicar el tipo de error encontrado.
\end{itemize}

\end{document}